# Q1 (descriptive): what's the process of acquiring the concept of "positive number"?
I think: (1) counting may not be natural. It's about making very precise judgement of quantity, which may not be needed in most cases, thus is not necessary to be evolved. (2) some functions supporting positive numbers may be natural. First, need to have the concept of quantity; then, basic operations such as "bigger/smaller than" [*--correspond to "set theory"? is that people's basic cognition? what about "group theory"?*].

``
to be read back: "infants have core cognition of number: the analog magnitude and the parallel individuation systems described in chapter 4 and the set-based quantification system described in chapter 7."
``

### Define continuity or discontinuity in the learning of positive number?
+ Continuity hypothesis(Gelman and Gallisel): 
  + **discrete numeral list** infants have the innate ability to establish a non-verbal counting list (**shown by ...what? chp4? **). Then they only need to map those representation into their own language that expresses this numeron list. Thus, learning to count should be easy (*after children demonstrate the non-verbal counting ability?*)
  + **analog magnitude representation** It has been shown that both adults (*to check: chp4*) and infants have a mapping between analog magnitude representation to numeral list (mentioned above); could that also map to positive numbers?
  However, if that is the basis of natural numbers, that requires iterative, serial process to construct a magnitude representation. Yet that seems not to be the case...
  > Is the magnitude representation based on iterative "counting"? 
  
  > typical task: distinction between M and N items shown to them (eg: dots on cards). Different from enumeration because the processing time for smaller/bigger number doesn't vary a lot, supporting a "parallel processing". -- *Chronometric studies of numerical cognition in five-month-old infants*, Wood and Spelke (2005)

  Other conceptual failures of analog rep (as basis of natural number rep):
  + can't represent infinitely high magnitude (*but is this generalization ability our definition of "postive number system"?? *).
  + inexact and subject to Weber fraction considerations, thus fails to capture small numerical differences between large sets of objects
  + 


+ Discontinuity hypothesis: after they are able to"use a stably ordered list and count each object just once, honoring the stable order and 1–1 correspondence principles...", it's still hard and needs the training of the culture to "figure out the cardinality principle—that is, before they figure out how counting represents number"/"learn the meaning of number words". 
> Wynn's demonstration: children are able to count (with English words such as "one, two, four, six, seven..."), i.e. able to answer **"how many toys are there?"**, but unable to use numbers to: (1) take out certain number of toys (2) to choose a card with certain number of items [--in summary, instead of mapping items to number, it's **mapping number to items**]

> In contrast, children are able to identify "one" and succeed in the tasks above if asked to distinguish "one" and anything more than one. -- so called **"one"-knowers**.

``What I don't understand (not correspondent to my intuition and no literature referred to): "...English speakers learning French do not learn the list, going through a stage where they know that it refers to number, but take “deux,” “trois,” “quatre,” and “cinq” to be roughly synonymous with each other, meaning plural or some."
``

# Q2 (explanatory): what's the learning mechanism that enables this acquisition?
